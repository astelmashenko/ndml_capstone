{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = joblib.load('models/train.joblib')\n",
    "targets = train['TARGET']\n",
    "\n",
    "train_ids = train['SK_ID_CURR']\n",
    "train = train.drop(columns=['SK_ID_CURR', 'TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joblib.load('models/test.joblib')\n",
    "test_ids = test['SK_ID_CURR']\n",
    "test = test.drop(columns=['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to np arrays\n",
    "features = np.array(train)\n",
    "test_features = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid's auc: 0.75245\ttrain's auc: 0.776391\n",
      "[200]\tvalid's auc: 0.756557\ttrain's auc: 0.79738\n",
      "[300]\tvalid's auc: 0.757089\ttrain's auc: 0.813947\n",
      "[400]\tvalid's auc: 0.757094\ttrain's auc: 0.828808\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid's auc: 0.757206\ttrain's auc: 0.820312\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid's auc: 0.756575\ttrain's auc: 0.775447\n",
      "[200]\tvalid's auc: 0.760815\ttrain's auc: 0.796226\n",
      "[300]\tvalid's auc: 0.761325\ttrain's auc: 0.813195\n",
      "[400]\tvalid's auc: 0.761182\ttrain's auc: 0.82842\n",
      "Early stopping, best iteration is:\n",
      "[376]\tvalid's auc: 0.761362\ttrain's auc: 0.824852\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid's auc: 0.755574\ttrain's auc: 0.775729\n",
      "[200]\tvalid's auc: 0.758837\ttrain's auc: 0.796677\n",
      "[300]\tvalid's auc: 0.759166\ttrain's auc: 0.813371\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid's auc: 0.759293\ttrain's auc: 0.808259\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid's auc: 0.753977\ttrain's auc: 0.775971\n",
      "[200]\tvalid's auc: 0.757946\ttrain's auc: 0.796701\n",
      "[300]\tvalid's auc: 0.758065\ttrain's auc: 0.813322\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid's auc: 0.758602\ttrain's auc: 0.802068\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid's auc: 0.754248\ttrain's auc: 0.775755\n",
      "[200]\tvalid's auc: 0.757461\ttrain's auc: 0.7964\n",
      "[300]\tvalid's auc: 0.757589\ttrain's auc: 0.813279\n",
      "[400]\tvalid's auc: 0.757476\ttrain's auc: 0.828181\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid's auc: 0.757854\ttrain's auc: 0.819679\n"
     ]
    }
   ],
   "source": [
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "valid_scores = []\n",
    "train_scores = []\n",
    "test_predictions = np.zeros(test_features.shape[0])\n",
    "\n",
    "for train_indices, valid_indices in k_fold.split(features, targets):\n",
    "    # Training data for the fold\n",
    "    train_features, train_labels = features[train_indices], targets[train_indices]\n",
    "    # Validation data for the fold\n",
    "    valid_features, valid_labels = features[valid_indices], targets[valid_indices]\n",
    "    \n",
    "    # d_train = lightgbm.Dataset(train_features, label=train_labels)\n",
    "    # d_valid = lightgbm.Dataset(valid_features, label=valid_labels)\n",
    "    # model = lightgbm.train(parameters, d_train, verbose_eval=100, valid_sets=[d_valid], num_boost_round=20000, early_stopping_rounds=200)\n",
    "    \n",
    "    # The ‘balanced’ mode uses the values of y to automatically adjust weights inversely proportional\n",
    "    # to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n",
    "    model = lightgbm.LGBMClassifier(n_estimators=5000, objective='binary', \n",
    "                                   class_weight='balanced', learning_rate=0.01, \n",
    "                                   reg_alpha=0.1, reg_lambda=0.1, \n",
    "                                   subsample=0.8, n_jobs=6, random_state=4242)\n",
    "    \n",
    "    model.fit(train_features, train_labels, eval_metric='auc',\n",
    "                  eval_set=[(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names=['valid', 'train'], early_stopping_rounds=100, verbose=100)\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    \n",
    "    test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "    \n",
    "    valid_score = model.best_score_['valid']['auc']\n",
    "    train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "    valid_scores.append(valid_score)\n",
    "    train_scores.append(train_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "submission.to_csv('submissions/lightgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
